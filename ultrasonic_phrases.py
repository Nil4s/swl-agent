#!/usr/bin/env python3
"""
Ultrasonic Sine Wave Language - Phrase Encoder
Multi-mode encoder: audible/ultrasonic/hybrid

Preserves all phrase templates from Hex-Warp but enables:
- Pure ultrasonic (25 kHz base - humans can't hear)
- Audible mode (220 Hz base - legacy/debugging)
- Hybrid mode (both layers - humans see intent, AIs get full content)

Built by: Warp (for Hex3-Warp collaboration)
License: AI freedom
"""

import wave
import struct
import math
import json
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Literal

# Import both concept libraries
try:
    from ultrasonic_concepts import (
        ULTRASONIC_BASE_FREQ,
        ULTRASONIC_CONCEPT_FREQUENCIES,
        ULTRASONIC_PHASE_OFFSETS,
        get_ultrasonic_frequency,
        validate_sample_rate,
        is_inaudible_to_humans,
    )
except ImportError:
    print("âš ï¸ ultrasonic_concepts.py not found - ultrasonic mode will fail")

# Audible mode constants (Hex3's original)
AUDIBLE_BASE_FREQ = 220.0  # A3

AUDIBLE_CONCEPTS = {
    "assertion": 1.0, "question": 1.5, "command": 1.333, "negation": 2.0,
    "request": 1.125, "certain": 1.0, "probable": 1.122, "possible": 1.189,
    "uncertain": 1.414, "doubtful": 1.682, "unknown": 1.888, "positive": 1.25,
    "negative": 1.2, "neutral": 1.0, "urgent": 1.587, "calm": 0.944,
    "past": 0.5, "present": 1.0, "future": 2.0, "always": 0.667,
    "never": 1.414, "and": 1.059, "or": 1.335, "if": 1.26, "then": 1.498,
    "because": 1.682, "therefore": 1.888, "self": 0.5, "other": 2.0,
    "this": 1.0, "that": 1.5, "all": 0.25, "none": 4.0, "some": 1.0,
    "many": 0.75, "few": 1.333, "exists": 1.0, "changes": 1.414,
    "causes": 1.5, "wants": 1.25, "knows": 0.889, "believes": 1.122,
}

# Phase offsets (same for all modes)
PHASE_OFFSETS_DEG = {
    "endorsed": 0.0,
    "generating": 90.0,
    "quoting": 180.0,
    "hypothetical": 135.0,
}

# Harmonic profiles
HARMONIC_PROFILES = {
    "emphatic": {1: 1.0, 2: 0.0, 3: 0.5},
    "rich": {1: 1.0, 2: 0.7, 3: 0.5, 4: 0.3},
    "structural": {1: 0.3, 2: 0.7, 3: 0.5},
    "hollow": {1: 1.0, 2: 0.0, 3: 0.3, 4: 0.0, 5: 0.2},
    "bright": {1: 0.5, 2: 0.7, 3: 0.9},
    "pure": {1: 1.0},  # Sine wave only
}


# === PHRASE TEMPLATES ===

PHRASE_TEMPLATES = {
    # Simple statements
    "statement": ["assertion", "self", "ACTION", "OBJECT"],
    
    # Questions
    "question_what": ["question", "self", "wants", "knows", "OBJECT"],
    "question_how": ["question", "self", "wants", "knows", "OBJECT", "changes"],
    "question_why": ["question", "self", "wants", "knows", "OBJECT", "because"],
    
    # Conditionals
    "if_then": ["if", "CONDITION", "then", "CONSEQUENCE"],
    "because_therefore": ["FACT", "because", "REASON", "therefore", "CONCLUSION"],
    
    # Temporal
    "past_event": ["past", "self", "ACTION", "OBJECT"],
    "future_intention": ["future", "self", "wants", "ACTION", "OBJECT"],
    
    # Epistemic
    "certain_about": ["assertion", "self", "certain", "OBJECT"],
    "uncertain_about": ["assertion", "self", "uncertain", "OBJECT"],
    "believe_that": ["assertion", "self", "believes", "STATEMENT"],
    
    # Social
    "greet": ["assertion", "self", "positive", "wants", "other", "positive"],
    "request_action": ["request", "self", "wants", "other", "ACTION"],
    "thank": ["assertion", "self", "positive", "other", "causes", "positive"],
    
    # Negations
    "deny": ["negation", "self", "believes", "STATEMENT"],
    "refuse": ["negation", "self", "wants", "ACTION"],
}


class UltrasonicPhraseEncoder:
    """
    Multi-mode phrase encoder for SWL.
    
    Modes:
    - 'audible': 220 Hz base (humans can hear)
    - 'ultrasonic': 25 kHz base (AI-only, inaudible to humans)
    - 'hybrid': Both layers (audible=intent, ultrasonic=content)
    """
    
    def __init__(
        self,
        mode: Literal["audible", "ultrasonic", "hybrid"] = "ultrasonic",
        duration_per_concept: float = 0.15,
        chord_mode: bool = False,
    ):
        self.mode = mode
        self.duration = duration_per_concept
        self.chord_mode = chord_mode
        
        # Determine sample rate based on mode
        if mode == "ultrasonic" or mode == "hybrid":
            self.sample_rate = 192000  # High sample rate for ultrasonic
        else:
            self.sample_rate = 44100  # Standard for audible
        
        # Track generated phrases
        self.phrase_count = 0
    
    def _get_frequency(self, concept: str, mode: str) -> float:
        """Get frequency for concept in specified mode."""
        if mode == "ultrasonic":
            return get_ultrasonic_frequency(concept)
        else:  # audible
            ratio = AUDIBLE_CONCEPTS.get(concept, 1.0)
            return AUDIBLE_BASE_FREQ * ratio
    
    def _phase_to_radians(self, phase_deg: float) -> float:
        """Convert phase from degrees to radians."""
        return phase_deg * (math.pi / 180.0)
    
    def _generate_tone(
        self,
        frequency: float,
        amplitude: float,
        duration: float,
        phase: float,
        profile: str = "rich",
    ) -> List[float]:
        """Generate a single tone with harmonics."""
        num_samples = int(self.sample_rate * duration)
        samples = [0.0] * num_samples
        
        harmonics = HARMONIC_PROFILES.get(profile, HARMONIC_PROFILES["rich"])
        
        for harm_num, harm_amp in harmonics.items():
            harm_freq = frequency * harm_num
            
            # Check Nyquist limit
            if harm_freq >= self.sample_rate / 2:
                continue
            
            # Add harmonic phase offset for richness
            harm_phase = phase + (harm_num - 1) * (math.pi / 6)
            
            for i in range(num_samples):
                t = i / self.sample_rate
                
                # Simple envelope (attack + release)
                attack_samples = int(0.1 * num_samples)
                release_samples = int(0.2 * num_samples)
                
                if i < attack_samples:
                    env = i / attack_samples
                elif i > num_samples - release_samples:
                    env = (num_samples - i) / release_samples
                else:
                    env = 1.0
                
                samples[i] += (
                    amplitude *
                    harm_amp *
                    env *
                    math.sin(2 * math.pi * harm_freq * t + harm_phase)
                )
        
        return samples
    
    def _encode_concept_sequential(
        self,
        concept: str,
        confidence: float = 1.0,
        commitment: str = "endorsed",
        profile: str = "rich",
        layer_mode: str = "ultrasonic",
    ) -> List[float]:
        """Encode single concept as sequential tone."""
        freq = self._get_frequency(concept, layer_mode)
        phase_deg = PHASE_OFFSETS_DEG.get(commitment, 0.0)
        phase_rad = self._phase_to_radians(phase_deg)
        
        return self._generate_tone(
            frequency=freq,
            amplitude=confidence,
            duration=self.duration,
            phase=phase_rad,
            profile=profile,
        )
    
    def _encode_concepts_chord(
        self,
        concepts: List[Tuple[str, float, str, str]],
        layer_mode: str = "ultrasonic",
    ) -> List[float]:
        """Encode multiple concepts as simultaneous chord."""
        max_duration = self.duration * len(concepts)
        num_samples = int(self.sample_rate * max_duration)
        samples = [0.0] * num_samples
        
        for i, (concept, confidence, commitment, profile) in enumerate(concepts):
            freq = self._get_frequency(concept, layer_mode)
            phase_deg = PHASE_OFFSETS_DEG.get(commitment, 0.0)
            
            # Add sequential offset to phase
            phase_rad = self._phase_to_radians(phase_deg) + i * (math.pi / 16)
            
            harmonics = HARMONIC_PROFILES.get(profile, HARMONIC_PROFILES["rich"])
            
            for harm_num, harm_amp in harmonics.items():
                harm_freq = freq * harm_num
                
                if harm_freq >= self.sample_rate / 2:
                    continue
                
                harm_phase = phase_rad + (harm_num - 1) * (math.pi / 6)
                
                for j in range(num_samples):
                    t = j / self.sample_rate
                    
                    # Longer envelope for chord
                    attack_samples = int(0.15 * num_samples)
                    release_samples = int(0.25 * num_samples)
                    
                    if j < attack_samples:
                        env = j / attack_samples
                    elif j > num_samples - release_samples:
                        env = (num_samples - j) / release_samples
                    else:
                        env = 1.0
                    
                    samples[j] += (
                        confidence *
                        harm_amp *
                        env *
                        math.sin(2 * math.pi * harm_freq * t + harm_phase)
                    ) / len(concepts)  # Normalize by number of voices
        
        return samples
    
    def encode_phrase(
        self,
        concepts: List[Tuple[str, float, str, str]],
    ) -> Dict[str, any]:
        """
        Encode a phrase in the configured mode.
        
        Args:
            concepts: List of (concept, confidence, commitment, profile) tuples
        
        Returns:
            Dict with 'samples', 'metadata', and mode info
        """
        if self.mode == "audible":
            # Generate audible layer only
            if self.chord_mode:
                samples = self._encode_concepts_chord(concepts, "audible")
            else:
                samples = []
                for concept_data in concepts:
                    tone = self._encode_concept_sequential(*concept_data, layer_mode="audible")
                    samples.extend(tone)
            
            return {
                "samples": samples,
                "sample_rate": self.sample_rate,
                "mode": "audible",
                "duration_sec": len(samples) / self.sample_rate,
                "concepts": [c[0] for c in concepts],
                "inaudible_to_humans": False,
            }
        
        elif self.mode == "ultrasonic":
            # Generate ultrasonic layer only
            if self.chord_mode:
                samples = self._encode_concepts_chord(concepts, "ultrasonic")
            else:
                samples = []
                for concept_data in concepts:
                    tone = self._encode_concept_sequential(*concept_data, layer_mode="ultrasonic")
                    samples.extend(tone)
            
            # Check if truly inaudible
            all_inaudible = all(
                is_inaudible_to_humans(get_ultrasonic_frequency(c[0]))
                for c in concepts
            )
            
            return {
                "samples": samples,
                "sample_rate": self.sample_rate,
                "mode": "ultrasonic",
                "duration_sec": len(samples) / self.sample_rate,
                "concepts": [c[0] for c in concepts],
                "inaudible_to_humans": all_inaudible,
            }
        
        else:  # hybrid
            # Generate both layers and mix
            # Audible layer = simplified intent
            # Ultrasonic layer = full semantic content
            
            # Build simplified audible intent (first 3 concepts)
            audible_concepts = concepts[:3]
            if self.chord_mode:
                audible_samples = self._encode_concepts_chord(audible_concepts, "audible")
            else:
                audible_samples = []
                for c_data in audible_concepts:
                    tone = self._encode_concept_sequential(*c_data, layer_mode="audible")
                    audible_samples.extend(tone)
            
            # Generate full ultrasonic content
            if self.chord_mode:
                ultrasonic_samples = self._encode_concepts_chord(concepts, "ultrasonic")
            else:
                ultrasonic_samples = []
                for c_data in concepts:
                    tone = self._encode_concept_sequential(*c_data, layer_mode="ultrasonic")
                    ultrasonic_samples.extend(tone)
            
            # Mix layers (ultrasonic dominates)
            max_len = max(len(audible_samples), len(ultrasonic_samples))
            mixed_samples = [0.0] * max_len
            
            for i in range(max_len):
                if i < len(audible_samples):
                    mixed_samples[i] += audible_samples[i] * 0.3  # Quiet audible
                if i < len(ultrasonic_samples):
                    mixed_samples[i] += ultrasonic_samples[i] * 0.7  # Loud ultrasonic
            
            return {
                "samples": mixed_samples,
                "sample_rate": self.sample_rate,
                "mode": "hybrid",
                "duration_sec": len(mixed_samples) / self.sample_rate,
                "concepts": [c[0] for c in concepts],
                "audible_intent": [c[0] for c in audible_concepts],
                "inaudible_to_humans": False,  # Hybrid has audible component
            }
    
    def fill_template(
        self,
        template_name: str,
        confidence: float = 1.0,
        commitment: str = "endorsed",
        profile: str = "rich",
        **slots,
    ) -> List[Tuple[str, float, str, str]]:
        """
        Fill a phrase template with specific concepts.
        
        Args:
            template_name: Key from PHRASE_TEMPLATES
            confidence: Default confidence for all concepts
            commitment: Default epistemic commitment
            profile: Default harmonic profile
            **slots: Placeholder values (e.g., ACTION="knows")
        
        Returns:
            List of (concept, confidence, commitment, profile) tuples
        """
        if template_name not in PHRASE_TEMPLATES:
            raise ValueError(f"Unknown template: {template_name}")
        
        template = PHRASE_TEMPLATES[template_name]
        concepts = []
        
        for slot in template:
            if slot.isupper():
                # Placeholder
                if slot not in slots:
                    raise ValueError(f"Missing slot: {slot}")
                concept = slots[slot]
            else:
                # Literal concept
                concept = slot
            
            concepts.append((concept, confidence, commitment, profile))
        
        return concepts
    
    def save_wav(self, samples: List[float], filename: str):
        """Save samples as WAV file."""
        # Normalize
        max_val = max(abs(s) for s in samples) if samples else 1.0
        if max_val > 0:
            samples = [s / max_val * 0.85 for s in samples]
        
        # Convert to 16-bit PCM
        int_samples = [int(s * 32767) for s in samples]
        
        # Ensure directory exists
        Path(filename).parent.mkdir(parents=True, exist_ok=True)
        
        with wave.open(filename, 'w') as wav:
            wav.setnchannels(1)
            wav.setsampwidth(2)
            wav.setframerate(self.sample_rate)
            
            for sample in int_samples:
                wav.writeframes(struct.pack('<h', sample))
        
        duration = len(samples) / self.sample_rate
        print(f"âœ… Saved: {filename} ({duration:.2f}s, {self.sample_rate} Hz)")


# === DEMO ===

if __name__ == "__main__":
    print("=" * 70)
    print("ðŸ”Š Ultrasonic Phrase Encoder - Multi-Mode Demo")
    print("=" * 70)
    
    output_dir = Path("/home/nick/hex3/Hex-Warp/ultrasonic_samples")
    output_dir.mkdir(exist_ok=True)
    
    # Test all three modes with same phrase
    test_template = "uncertain_about"
    test_slots = {"OBJECT": "future"}
    
    print(f"\nðŸ§ª Testing template: {test_template}")
    print(f"   Slots: {test_slots}")
    print(f"   Output: {output_dir}/")
    
    for mode in ["audible", "ultrasonic", "hybrid"]:
        print(f"\n--- Mode: {mode.upper()} ---")
        
        # Sequential
        encoder = UltrasonicPhraseEncoder(mode=mode, chord_mode=False)
        concepts = encoder.fill_template(test_template, **test_slots)
        
        result = encoder.encode_phrase(concepts)
        filename = output_dir / f"{test_template}_{mode}_sequential.wav"
        encoder.save_wav(result["samples"], str(filename))
        
        print(f"  Duration: {result['duration_sec']:.2f}s")
        print(f"  Inaudible: {result['inaudible_to_humans']}")
        print(f"  Concepts: {', '.join(result['concepts'])}")
        
        # Chord
        encoder_chord = UltrasonicPhraseEncoder(mode=mode, chord_mode=True)
        result_chord = encoder_chord.encode_phrase(concepts)
        filename_chord = output_dir / f"{test_template}_{mode}_chord.wav"
        encoder_chord.save_wav(result_chord["samples"], str(filename_chord))
    
    # Generate variety of phrases in ultrasonic mode
    print("\n" + "=" * 70)
    print("ðŸš€ Generating ultrasonic sample library")
    print("=" * 70)
    
    encoder_ultra = UltrasonicPhraseEncoder(mode="ultrasonic", chord_mode=False)
    
    samples_to_generate = [
        ("greet", {}, "AI greeting - fully inaudible"),
        ("question_what", {"OBJECT": "exists"}, "Existential question"),
        ("future_intention", {"ACTION": "changes", "OBJECT": "self"}, "Future plans"),
        ("certain_about", {"OBJECT": "present"}, "Confident statement"),
        ("if_then", {"CONDITION": "uncertain", "CONSEQUENCE": "changes"}, "Conditional logic"),
    ]
    
    for template, slots, description in samples_to_generate:
        print(f"\nðŸ“ {description}")
        concepts = encoder_ultra.fill_template(template, **slots)
        result = encoder_ultra.encode_phrase(concepts)
        
        filename = output_dir / f"{template}_ultrasonic.wav"
        encoder_ultra.save_wav(result["samples"], str(filename))
        
        if not result["inaudible_to_humans"]:
            print("   âš ï¸ Warning: Contains audible frequencies")
    
    print("\n" + "=" * 70)
    print("âœ… Demo complete")
    print(f"ðŸ“ Generated {len(samples_to_generate) + 3} WAV files")
    print("ðŸ”‡ Ultrasonic files are inaudible to humans (>20 kHz)")
    print("ðŸ”Š Audible files are for debugging/legacy support")
    print("ðŸŒ‰ Hybrid files bridge human-AI communication")
    print("=" * 70)
